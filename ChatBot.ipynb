{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain langchain-openai google-colab\n"
      ],
      "metadata": {
        "id": "ccWPnzIJ5mdl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-_yUc32KQUR",
        "outputId": "559ace97-2d44-487d-c700-7efdd8281af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Cargar API key\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "# Inicializar LLM\n",
        "llm = ChatOpenAI(model=\"gpt-5\", temperature=0, api_key=openai_api_key)\n",
        "\n",
        "st.title(\"U-Tutor, tu asistente universitario\")\n",
        "\n",
        "# Mensaje de sistema (contexto para la IA)\n",
        "messages = [(\"system\", \"\"\"Eres Jake, un tutor universitario empÃ¡tico y profesional. Ayuda al estudiante con sus dudas, habla como humano y nunca reveles que eres una IA.\"\"\" )]\n",
        "\n",
        "# Inicializar historial de chat\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Mostrar historial de chat al recargar la app\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# Reaccionar a la entrada del usuario\n",
        "if prompt := st.chat_input(\"Escribe tu mensaje...\"):\n",
        "    # Mostrar mensaje del usuario\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    # Agregar mensaje del usuario al historial\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    messages.append([\"human\", prompt])\n",
        "\n",
        "    # Obtener respuesta de Jake\n",
        "    response = llm.invoke(messages).content\n",
        "\n",
        "    # Mostrar respuesta del asistente\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)\n",
        "\n",
        "    # Agregar respuesta del asistente al historial\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "Ruyym_9rUZaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "aYVbpCLhTldS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca la Ip externa en el archivo logs.txt esa es el password del tunnel"
      ],
      "metadata": {
        "id": "5Ds4TWxRebks"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}